{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 6: Lab Exercises for COMP499/691 Conversational AI**\n",
        "\n",
        "The goal of this lab is to further familiarize yourself with SpeechBrain.\n",
        "In the previous labs, you had to properly complete some \"prefilled\" code that implemented some speechbrain model. In this lab, instead, you will do a little step ahead and write a full training recipe from scratch.\n",
        "\n",
        "## **Task Description**\n",
        "\n",
        "This time we will work on speaker identification. The task is very simple: you have a speech signal in input, and you have to tell which of the N speakers in the pool is speaking."
      ],
      "metadata": {
        "id": "Z8gjO212AV4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pictures-Page-1.drawio (3).png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWUAAABPCAYAAAAzxdRfAAAAAXNSR0IArs4c6QAABqt0RVh0bXhmaWxlACUzQ214ZmlsZSUyMGhvc3QlM0QlMjJhcHAuZGlhZ3JhbXMubmV0JTIyJTIwbW9kaWZpZWQlM0QlMjIyMDIzLTAyLTE0VDIyJTNBMzElM0EwNy4zODhaJTIyJTIwYWdlbnQlM0QlMjI1LjAlMjAoWDExJTNCJTIwTGludXglMjB4ODZfNjQpJTIwQXBwbGVXZWJLaXQlMkY1MzcuMzYlMjAoS0hUTUwlMkMlMjBsaWtlJTIwR2Vja28pJTIwQ2hyb21lJTJGMTA5LjAuMC4wJTIwU2FmYXJpJTJGNTM3LjM2JTIyJTIwdmVyc2lvbiUzRCUyMjIwLjguMTElMjIlMjBldGFnJTNEJTIydE5ONG5iSUExcGk2bGZXamN6QnIlMjIlMjB0eXBlJTNEJTIyZ29vZ2xlJTIyJTNFJTNDZGlhZ3JhbSUyMG5hbWUlM0QlMjJQYWdlLTElMjIlMjBpZCUzRCUyMjJhQklfQktMQkI0T3pCWHdqcUw0JTIyJTNFN1ZqUmJwc3dGUDJhUERZQ0hBaDVUTnBtcTlSTmxmS3c3V2x5c0FOZURFYmdOTW0lMkJmdGRnQnh4b2wyNXMwdHBGYW1NZjI5ZjJPZWZpNEJHNlRnJTJGdkNwd25Id1NoZk9RNTVEQkNOeVBQOHh6SGdTJTJCRkhHdkVkWU5wamNRRkl4cHJnQlg3VGpXb0I4WTdSbWhwZFpSQ2NNbHlHNHhFbHRGSVdoZ3VDckczdTIwRXQyZk5jVXc3d0NyQ3ZJdCUyQllrUW1OUnI2VG9PJTJGcHl4T3pNeXUyWEdLVFdjTmxBa21ZdCUyQkMwTzBJWFJkQ3lMcVVIcTRwViUyQndaWHVweHl5ZGFUd3NyYUNZdkdlRFZBeDR4MyUyQm05clhLS3Q3UVllUUZPOHhGYVpPdFNmVUdkUThURldyWEVxblJIWUE2MllSR1dUR1I2TyUyRkpvT0NyRUxpTlVUZU5DNTMzQ0pGM2xPRkt0ZTdBRllJbE11VzdlTU02dkJSZEZOUllSVE1OTkJIZ3BDN0dsclpZZ0N1bDZVNjJuV2pjdEpEMDh1WGYzeENoNGtZcVV5dUlJWGN5QWNEYWVLamVhRDZvamFGZjZPdUMlMkJVZGcxc2lVdGRRT05ZVzJxJTJCRFJSd3pzVU5QWDlNcUNPREIwJTJCS1FFTDZxb29aQ0ppa1dGJTJCMjZDTGhuRUhhazJmZXlGeXpmTTNLdVZSNXhQZVNXR3JVTSUyQnBKckpUQ3hjeGxaWmZMaUM1b0J5TThXaUg2dU5JRDMwUURDSTI0dmpUc1lkbXA4ODB0TVFKendLV1lsZEVWTWM0NCUyRjIwcUl1a21IU2t1TXZ5blZyWmZFZVk2T2dDJTJGcE0yamJacE01SFJNNGRyQ0hNV1oxQ05nRXBJT0xSUWJvWjA0blBka0RKQ0ttWDdzc2RXZTRCMEFNS1JUVEx5dXhuZzlHUUFHaUFEJTJGQXN5SUNOejlmQldsSEZjbGl5eWVlOWpwR1BtQyUyRmhvYmRmdjJhM0JmdFBneUhVc2c5dlVCJTJCZ2lmM2VqVHNJWFJLMHplNGlzQ2Q2ZWZPN1ltelJueDlRaTJqeXRYaTdmN0JuNXpxTU9KOSUyRjB2M3h0b21lelB5SGZlZFRoNUFzNzhwWDUxbjI5UnhWQyUyRnRnYzFFZmJGeTM3QkQzMjhjS25uWExwVVRYclk3dWJNSyUyQlo3YUQ3eTZDUDdTRiUyQkdKaDNQcHZ1ajIlMkJLN2hEOVBicmRGeDBGbWtLQ3klMkJUMHJ0ZVNRT0VQV0FLdFdZVjQ4STVsaERGdnpsNkhSSHBnOG5PciUyRkVXVng3NnUzUnhhVFRmSGYlMkJYQVFjJTJGOTNKdjV2M2pnUEJzMVBQUERjQWVPMjcwMzZMaWtUSEN1aWl5dGJsTk9XWFdQMTVRJTJGaUpKVjF3Ym9aaTJrRkNsMDRLcGhnYU50WE5uQlpDbWhHN3lyN2g3TzgxS3E5OW9GTHZQNmptZkREc3BDaTJyQ3VVRWRnMEE1a1ZMZEVNM1YxcjNsZnI4ZjUxbThwY2R4QkF2d2xsQ0IlMkY0Ukt6R0N6U3c4RlYlMkZBM21ZVHUxeEpteFB3S2d0SW91VW94TENTN0l0UUFkYk9LTnRBellEWkd3YyUyQmV1QzY4UVFTVFFSNERVRzN1bkdvJTJGTkZkMzZQWUglM0MlMkZkaWFncmFtJTNFJTNDJTJGbXhmaWxlJTNFsB6P/wAAIABJREFUeF7tnQd4FFXXx/8721t6AilACCBdqtJEuiAIIogirwoKSvFDhVdpIggKKAKKKGIBeQUVURGUIgpWFJQuvRNCet3dJNtnv+fcdWNCzSab7Ca593l42M3O3HLuzG/OnHvOuRKXy+UCL1wCXAJcAlwCASEBCYdyQMwD7wSXAJcAlwCTAIcyvxC4BLgEuAQCSAIcygE0GbwrXAJcAlwCHMr8GuAS4BLgEgggCXAoB9Bk8K5wCXAJcAlwKPNrgEuAS4BLIIAkwKEcQJPBu8IlwCXAJcChzK8BLgEuAS6BAJIAh3IATQbvCpcAlwCXQEBDOS4uDuvWrcMdd9zh85nasWMHmjRpAmrjWuW5557DqlWrcPjwYdSpU8fr9g8dOoT7778fZ8+exaJFi3Dy5El8+OGHXtfDT+AS4BKoWRKosVC+9957MX36dHTs2PGqGXc6nWjWrBkee+wxUBQ6HedtKQ7lwsJCOBwOBAUFeVsNP55LgEughkmgykA5NDQUr776Kr766iucP38ejz/+OGbMmIH9+/fj0UcfRZ8+fbBv3z7k5eXh7bffRvfu3dnxFy9exIoVK9i0er7Xr18fs2fPRmxsLF5//XUMGTKkxLRv2bIF69evx/z589G3b18cPXq06HeVSsXqrF27Nvtb8e8LFizAu+++i7CwMAwbNgwfffTRVZrykSNHMG7cOGRmZrJz582bh4EDB9awy44Pl0uAS+B6EqgyUI6IiMDYsWMZxJKTk5GQkIDc3FycPn0abdu2xfbt2xmYN23ahOeff579/XpQJki3aNGCmROupSkTUKmt3r17o1evXqye22677SoIF4cy9aVz5844ceIEatWqhUceeQR79uwpAeX333+ftfviiy/ioYcewrFjx9g5586dA42PFy4BLgEugSoF5R9++AFt2rRhs0baKGnJBoOBacWkIVMhM4FCoUBGRgaD7rU05RtBmeDarl07BlNBEJi2e+DAASxbtuyGUN64cSO2bdvGHgpU6CHx1FNPlYAymUFat24No9EIiUTCjuvUqROmTZsGMqfwwiXAJcAlUKWgTJpnw4YN2ayRZknf8/PzMXjwYAZfT9FqtSCbLpk6vIXy8uXLMXnyZGZaoEI2ZYJ8SkoK5HJ5CXNFcU2ZFgVJO1+9ejU7b+/evUwbLr7QN3r0aAwfPhyJiYlFfR0wYADuu+8+jBkzhl+NXAJcAlwCgZ0lrrj3hQfC14LynXfeyTRm0j6tVisDZ3Z2NlauXMmg+N5777GpfuGFF9jfb6Qpd+jQAUuXLi1h1iAtlhb9CP4EfKozOjoaNpuNtUXA/vrrr5l2TBozlc2bN+PZZ5+9pqZMfSUtnAq1N3PmzBpjVz59KRf7T2fi7OU85BgtcDhFfhsGoAToPU6rViAuSoeWCeHo1CIacpn7muWlYiVQLTTl9u3bM9c5ckFbu3YtswHT4tynn34K0nx37doFs9nMTAVkQyYokxmEFub69etXJGGyB5MNmWzWHvMC/UgmjG+//RYbNmzALbfcwuokezO1NXLkSHZ8eno6evTowezEUVFRePDBB5m2XlxT/uCDD5hNmR4OI0aMYL9Te3QMLWRW55KWXYCvfjmHHKMVjeNroU50CEL0asik/EYPxHmnnS8KzTakZZlw/nIWElNzcU/neHRtFRuI3a1WfaoWUH7ggQeYpknaKcGUNOQuXbqAXNFIy83KykLdunWZmxt9JjjOnTsXixcvxiuvvIKJEyeySSXbLtmmPd4anpn2nJ+UlISdO3cyrw+qr3///liyZAkzVZAnx6xZs1jdwcHBzMPizTffZOaT4n7KHu8LqlOtVjPvD1qgrM7l6IVsrNp8DB1vjUebJvymropznZGTj10HzqFuLR0e6n1LVRxClelzQEO5NFIkbZO8Jc6cOVOaw/kxlSyBC6lGvPH5AQzs1hzxMWGV3DpvztcS2LbrOGLC1Li/h3tthxffS6BaQNkTOed78fAayyuBV9fuQ7MGMWiaUKu8VfHzA0ACTlHE+u0HMahLfbRuFBkAPap+XeBQrn5zGjAj2vV3Cvafzkb/rs0Cpk+8I+WXwPnL2Th44hKmPdy+/JXxGq6SQJWHMp/TwJXA658dQJumdVEvunovYgbuDFRczz7ffhDDezZEw7iQimukhtbMoVxDJ76ih11gtmP2yj0YO6xzRTfF6/eDBHYfvohwvRQDOsX7ofXq3SSHcvWeX7+N7nyKAet/PIehfVr5rQ+84YqTwJnETKSkZ2PMwOYV18h1aia3U/Lzb9q0aYW1XTyh2JWNUNQweWCRVxVFDvs6RQKHcoVNa82u+MTFHGz7KwkDu7Wo2YKopqMnv+WT51Lwf0NvrfQREozJt598/cmNtSLgfCMoUxAZpUsgd9q0tDQO5Uq/AniDZZIAh3KZxFZlTvInlHfv3s2Ct0RRZGkQKFDrZnAmrZYie+kcyvC4Zs0altRMr9eziFqKxqXIXEpENmnSJBbY5fHqstvtLJaA4hKmTJnCfiMoy2QyDuUqc8XyjoJDuXpfBP6EMkmWcsZs3bqVCZlSHXjgTIFgFOFbvFCgFkXiUs4ZgjDlp6HAsgkTJiAkJIQFj7388stITU1Fo0aNcPz4ceTk5BRBefz48SzRGQWGFS8cytX7Gq92o+NQrnZTWmJABOVvNm7EsjlP+G2gOp2OJSTzFIIzRdaSaaN4oRQLMTExLK0CBZqFh4cX/UxQ/umnn4qyT3bt2hXPPPMMS3xGmjLtQPTll1/iu+++Y5oxh7Lfpps3XF4JcCiXV4KBfX5V0pRJkgcPHmRQpvS/pElTbnPa7IKgTOaI+Hi3Fwlp4GQzpvzptA2dVCrFoEGDmLnjylJhmrLVanXR9ke8VD0JUO6MQC0cyoE6M77plz+hTDZlsvESt0prU/aMmuzDc+bMwd9//41vvvmGQZny2VAOdSq06QRpx2RvJrs15VKn/1977TWWYrdSNGUOZd9cpP6ohUPZH1LnbZIE/Allb70vKO/6woULWdZIMnF8/PHHbLs3SmBGUB41ahRLHkbbzLVs2ZKZPyjro2eh7/fff2efCeSRkf+GlnNNmd8LV0mAQ5lfFP6SgD+h7K2fMnlckPZLm16QOYJyodOiHWWNJChTKl0CNeU5Jy8OWgC80iWONr64dOkS8+AguzUVyt2uVCrZZ1pEpG3gfFEkXFP2hRj9UweHsn/kzlv1r6bsS/kTlAnyHtD6su6y1lWJUHYBLgng3pqONlqC5wt9olL0U1lHU8PO41D2fsJPnzyGV196DieP/c1skrF16uG/M+ahS7fe3ld2kzNOHD2MiWMewI49p3xet78r9Kem7MuxE5RpQwza5ShQSoVDmQzxxXfxcLmAggIHtFop+3terg1BwXLQPqLFjwsUAQVyPziUvZ+duzo3xePjJuGBh8ew6+27zV9h2jOj8euBCwgO8W2+5/JCmR4a9LodiIVDueJmxWdQJtiS9usBK8GYnDpMRiuCg5WQCBL23WCwQxAkEAQnpIIUl5Is0OpckAoyxESrIREIzhU34OpUM4eyd7PpsNvRop4Wvx1MRGSt6KKTL54/gzr1EnDi2GFM+b9RTGs+cngfTAYDZi14Cx06d2PHvvvmfGz88hNIIEHnrj0xfe4iyOUKHDm0D7OnTIDBkAelUsXO6dilO4pDmdoe9UBfdOt9N5546nn8vGMrFs97ATa7DXXq1ceCJR+wPn204g2cOnEUx48eQvfe/TF5+sveDbKSjq4uUK4kcXnVjM+g7HAAtBeozSZCqZTAbHaisNAFh8MOnVYJlVrGfktNNUMQpBAkDqSkOqFWSREU7IDRIEFcHRXCw5WQSDwGDa/GUuMO5lD2fsonjBqCtNRkjHryGXS6o0cJOBNEB/dpj1XrtjEw7/zuG7w2dyq+/+ME+7x4/kx8vvk3aLQ6ZpYg8D46ZiLuu+s2jHziaQwe9gg2f70Oyxa/jO27jpWA8uypT8HpcOCVxe8hKyMN/bq2wKebfsEtTZpj1btLsH/vH3hn1ZdYs/JtvLNkHr7Y+jt7UARq4VCuuJnxEZRdsNsJygIuJxUAAqBRSyCRSGGx2BEcrIZUKsHp0/nMrzAlxQpTvoiwMBWkggilSoRCJkNMrAphYXLA5YJcIUAu5yrzjaaeQ9n7G4M01nVr3se2b77E4QN/IaFRE0yYNAP97hnKIPrwkJ4sMT8VgmizOmrsOZaKhXOnoX7DW/Dk/01hv5Gmu3L5YqzZsBMWi5lpzGRqyExPRbf2CTieZC6C8ujxk5mZZNVnWyGVybDxizUM3h9+uoXVVViQj/aNI3AksQCf/W8FfvphC1Z+5g4hDtTCoVxxM1NuKDudLogiIDqB/EIXsrMKUFAggULhhEIhZyBWq2SgneT1QTLkmxwwGBxITDQjLi4I+/blQR8kR3w9sp1JUK+eGrVqyyA6rYiI0CEyUs6XAK8z/xzK5bsxCKbfb/kaLz4/Hh9/+QMUCiVIk/5p37miilvVD8Kmnfsxf9Z/cWj/n9BqdW5gO52IiIzChu//wpaNn2PtR8tBwCeQkxnkRLKVQXn4oDsZrHv1HYjX3/4fO5dg/taiuQgLiyhqx2Qy4LvfjjJ4H9y3B4uXXx1BVr7R+vZsf0PZW7c4346+YmsrN5TJRkxagt0uYvv2HDRsqMXl5HxcTrIiKEjKNGOJoER4mBQ6nYCMDAGpqYXIybHDZBJhMDih1coRES6DWu1EQgMlGjRQwOWyQaNRIKGBFsIVRuZ//TYqVjiBXjuHsnczlJqShDMnj+HOnv1KnDj6of7oc/dgtGrbASMGd8eBMzlsbcRms6JFXS32nsxgmnKjJs2Z2aN4SU9NRu+OjbFxx140aNQUaamX0aN9gyIojxx2F/tt1LC+eH7mAvTpPxibvvwE2zd/heWrN1w1gLWr3mHwX/TOx94NrpKP9jeUvQ0g8VY8N0rduWnTJkydOpUlMLr11luZz3OTJk28beK6x5cBysVc2VxAWpobnqmpduzebUJoqAZGUwHyTTaILgFSiYxpwnq9BFabBAX5UqRnFEJ0CsjJFmEwmhEUrIbLaUVcXTUS6kug1rgQpFfBYrWibl0l6tVV44pcID4TQFWuiEPZu9m7cO4UhvTtiIVvfYRe/QYx8O77cxcmjBqKNV/tYArEkL634433PmXmDILn+8sWYssvh7Fz+7d4Z/HLzFyh1enx+ZoPIFco0KJVezwypBd+O5QIqVTGFu9WvrsYhy8YceHs6SKXuAN//cE+f/vTQZY+8p7urbHu218Rn9CILRRu/GItXpz3JjiUSzenZUnfWbqa3UddD8rJyclo3rw5tm3bhg4dOmDWrFn4448/8OOPP3pT/Q2PLQHlKzVQukiv9C12MV9jF+w2F44dy4fNJjA78PnzEmRk2KBWK5GcbIRKpYbN5mDasV4vY/bjEyedUMhtTKu2WASYzRJIZVK4RBE2mxORkS5ERNih1ytw4YINUVECQkJciKoFNGsSBIuV6lMAECvUfa64G9+VLn0kTZKT6HSBZHHzh4WLfFIqxAfb31CmPLSU6PtaJVBzX/z+yw4sWzQH586cYtcQeT6Mf2Y6et99LzM3PPPkcPS86x5m1yU3IPKKaHu7e0urFUsX4Ov1a0D5E+o3aIQFb3yIqNoxmPL0Y9j7x68IDg3FtNmv461FcyA6nZi94O0SfsoLZj+HlORLWPbh+iLvC7O5EFqdDrPmvYV2HbpwKHuBNm/Sd/oqn/J//vMf/PnnnxgyZAjrKSU6ooRFSUlJXvT8xocWg/K/IRz0yemQoLDQicICBwrNgMFoQ1SkAr//ngeNhn4TodPrIEgo1FADCVQ4dNiGhg2lyMuzQyYTIIpOtlhnNgM6nRxpaVLo9U7YHSJsVqpDgNMpYW5wUsHFFgNjYsiFToKz5xyoXUuKyChaCLFCpxWh1ioREe5CcIgcQXqCc0UUFwoLHazPUqkAhUIKlUpCa4/Mu4Q8QwjGx46ZoNFIUb++mn0vLLRDq5NBUhQUU/wRVzHhMf6E8kcffYRx48Yxp3vSFkaOHFliMgIVyje6YgjKTz/xIH7YfbIiLqxqVafHfNEsNAu9evXy29hKk76zovIp06App8bhw4fxySef+EwGJTRlk8nBAHP+nBk2hx0qhRpmC5CXZ0FwsAxOWq2DFGYzQUuKhAQVcnIsKCyUIzfXDKNRj4gIApcduXkSuESyJwuQyUTodXJkZMogFRwQBAIf2ewIyrSORxqnCKkggUotIiKCbM3kwSGFIBQgurYWiYnZUGvkUKmAli3U0OklCA5WMFD6rrhgLnQh8ZIZubkiNBoBMqkEMrkIqUyAwy7A5RKRn2+HQqmAVqtAaIgMWZkFiIxUQiZ3ISPDjtBQJeRyICfHgbw8WrCUISpKxR5QHvM4Qd5odJt+6NiyFH9Cmfrbt29ffP/99wgNDWX/isO5qkK5ukbgleX6utE5/rYpU99KqylXVD5l2q2E8mT89ttvLF+zrwqDMpkO9u8vgNnsYsAk4Op0NijkSoSECNBqBVht7t/Cw5QwWxwgv2TRJeLsGSAzU4RWC6SnyyEIDqZhWqwi07YJOFKpE0aTEnKZAKMR0GqdMJsF2B0CM4+Q9ilXONlnhYLOccJBX0UJ4uLs0GpkSE42w2qXoE0bFcJCRSgVAusHadcmkw02qwCNVsJMI3FxGrY6HhIig9UiQqEUkJ1thcEgMi2YzCk6nRQKhcB8qknDZQ8HF72O5EAUlbBaKeqQxuOC6HIiLEQNi8WBnFwL9Ho1YqIFpKRaEaSXwWp1weGUwum0MVu5WkMLnE7Y7VIkJRmhVMgQG6tkbn7krZKQoMaBgwY2Xqo/OlrDtHHqL0E7M8MGuYLqE3H6NPl5u1CnrhJBQdQfCaRSMt8A/oYyXYx0Y5hMJnY9Fofz7d0GVrk9+sobgeerm7Iq1ONvKHubvtPX+ZQp49zcuXNZpjlKiO/LwqBMtuC/j5gRFeX2zbx82YmYaMApighmIdACpIL79V2pcqumDocTNhtwMVGO1BS3C5wgKJkWbbXIAMHBAEXucoIgIjdXBY2G7MnkqSEwjddiBfudLK4SCe23JTAPDHooECHVGgdCQwsQGixj7nb5+SJuaURQFfDTT1ZoNDLm+RFXR4LatSVITnZBrRJx6VIhtFolCgpcDHZkhgkLUyA6WsZMJTnZpMGSWcXOoG40uoNYpDIrWrdRQZCAPaB0OgK+yOqJjJRAkEhhMNoRFUXtSpiZxmJxQqOWwWIloEqg0Yiw20SYLVZo1GpotO4IRdKgtVoZ7DZqW0REpJKFmlPfsrJdzFWQoO9w2hAbEwYjvbWILnTpLENKqgvnLzhgt9khijJERoro3j3yhlCmhYfKeK0kd68r83HTw+KdDz5BrjyBb5zqy7s1gOryN5TL6n3hi3zK5H3x4osvsrdE2u/P14VBmQBL2mp2Ni24SXDylBFhIS7m6B4UrIBSKYfTbkNIiPqfRSsRVpudHXv5sgRJl2xQaWTIzKB66DVfhEYHOOwyBi1aLMvNo3qccIkyCFIyVZDWZ4PBIGdWWJ3WgYJCKbMd001us8mh1jpQO8rCHgai6ECDhiqYjCLyTRIEh1rQrm0Q5HLKoeEWC5kE2Od/zLme72zBki21lQwDZwdfETxosUiQmWFmniP0NkDnGo0OKBRWhISqYTU7oQ9SQCaVIvFSPvOnVqm1qF1bwcbtAmnlZgbyBg3UzMRBsDUarQyo1JzF7EDDBhrIipkzPJ1299ndz5ILju4xsi7/M06uKfv6duD1lVYC/oayN37KvsynTDmUyQ3u119/ZTuXVES5yiXu+HETs42aC8Fe08n84BRJawS0GiWUSrd2Z7M64BQlOHPWiqRLTiiULihkGjicpCXSq78MJoMEdqeI7CyBwUguExEUJIPoksBilSBY70RyMplKRPZKXlAIhIRYUStKjaQkG0LDSOssRI/uIbBYSYO2IyPdgdrRMjRtqv0HUr6N+qN+ktmEIFqQDySnmCAIMmZDDg2WQqdXwGgoYOYFeogVFLqg04gIDZMiJESDjAzywbagbduwEg8L6iyZOchcQt4rvvDH8DeUq5tNuSJusOpap7+h7I1cfZlPmcx1o0ePhkJR0tGAXOWK7/3nTf+uPPYqlziiJ2ljf+3NhgA54uuTfZZsuDKo1GSHJSjTgiCQm2tBejotfLmYC1tsTBDyDBao1QKrIzUdCNI5kZqqYIpqUJBbzaN6nA4nVCopMw+Qxi2XO5j/ZkQkEBbqju4jCDscZnTtGgKlQgKzxW34DQ11C6QissoV6dQut5cFacnHjuVAr1chqpaK2ctp8c9kciIqUoa9+7LQpUsUsrLsUKqAIL2c2bXJXn2l/4VvHx/+tSmvWrUKtMtvoHhfPPfUo0ho6A6ZvrKsfn8pCxqZt+T9Mt0rZNLbsmk9Bg0dgaOH9+PZsSNYOk6r1YIR93ZHUuIFLFm+Bi9Nn1jmNJ1//LoTCY0ao3Z0HIv4O3/2VJn7W6ZBenlSVYLyjYZWpfIpW61OyGTk/cAMAwxCpLqrVJRYyAmjwcq8J86ft8DhdMLhUMFgdCAqUon0DDPMhSLzQ1apHHDYlcgzuBARqYJWI8BqNTNvjtq1RJw8WQCXRAepQIEi5F5mh/kf6LdoqYVeTzAney0tuLlB7Gu43WjSyMs4J8uOzCwrGjXSw2IhG7MNNpsLcXGk0ReiTh0NTCY7e4sgGFdW8bemHEh+yhUJ5eNHDmHx/BksHwUB2mjMQ2hYBE6fOAqK2Nt1OIkpG56/l2X+x4+8D2OfnobW7TqAfJepHZ0+qCxVVco5vobyhQsX2O4fZBJ49NFHK2UM1EiVy6dcQtNzkVeGC2q1jNlOs7ItkIA8IICjR/Kg0QYhK8uKevW0MJnMyMq2Q6kALBYZsrMLYbHK2bmxMUrodC7mzUH5LsjMkZ7mgqnACqVcAodoR0iwBOnpdjRtqkS9erp/zAD+C6722KRJ+yfvCU/uZ7ct222Udtt5K/Nx4V9N+WZ3TWW7xBWHMmmw058dA4qiqx0bh+Yt28JiLmSa58VzpzHzuXHIzEyHVqPFzHlL0fa2TizpPQWB9OgzAPv2/IbMjDS8+M9v/e+8FQZDLlq1vZ2FSpOmvGH7nxjStwModDu+fiNMn/M6Xprm1pTpelm68CUWEUhBJCOfmIjHx09mf6cAkh3ffcMCpm7v3A3zl7yPlSuW4K2Fc1ArOhZTZ72GpMTzRZoygX/WlPHIyc5iaUEnTX+ZBbdcr79de9x1s6nxye++hrJnYbpnz55sI9PKKlUOylcKxr3w5AYQFbNZRHq6FWfOmOB0EoydCI8Q2Gt9QYETomhHfj55D1iQnua2M9etJ0ewXoaISAq9Jl9fAWfPWKFUi8jMcCA83IZGjUJw+rQJ4eESxMcHrrZQWRfO9drxt6Z8o/H7E8qf/m8Fvt3wGdZ+tROFhQV4YMAdDLwEZUrNOWLkOJbknsKbx1MCor1nceHcGdzbqy3eW/sN7uzRlyUZojSa6779jSUJ+uKTlUxTLm6+KO5CV/zv27dswIfvLGIh2VaLGff0aMOi+HKyM7HolRn4+oe/2AN8aL9OGPf0VAwY/CAGdGvF+keassd88fKiFezvT01+AffcNxxnTh3Hg/fcgZ1/nkZmRvp1+1sZ16WvoewvTbkyZOVtG2XIffFvE//ktceePTlIT6cgEwdq1ZaiVctQyBVkviCPDjtOnczH5WQDmjQNg0wqICxUjohIsgtLUau2AtlZNhQUWpB4wYamzRSIilJDqRRgtTiYzy/fKOra08qh/K9cimvKpMmSVvvY2GfZAZSPgoD41H9n4u6uLXHwbC5LM0uFtN1pL72OkNBwDB/YlSUjonLq+BGMfeRe/Lz/vNdQpp1MGjdrWdR+vskItUbL2jQXFrB8zFQoO11sXF2Me2b6NaE89umpGNSrHeuv5y3sgQFdMHbiVNSJb3Dd/noLgbIc72sol6UP1fWcckGZvbYDyEi3sRScCoWM2aCbNguC6KQdRmQsau3QIQMuXTKhdeswtnjWsKGOBYmIIuXNUCEtLZ/lXzaY7IiLVbEgCV5uLgEO5WtD+bEH+2HgkIcw5EF36PeHyxex5EAPjRyLYf07s8U0TyFNes7Cd9giIWWLo11JqNBefp7v3mrKT/xnIPoNHIqhw0eVmER6MLw2ZyrOnTnBIJuclIiHH3+KLU5eS1O+f8TjmDR2BHsweArVfVf/wWjVruN1+3vzK6f8R3Aol1+G16uh3FCmitPSrLh4sYDZW8ls0bx5GOx2MxQKFYwmG44dzcPFC/lo3CQYQUEC6tYNYkEbBOXwcBXS001QKCVwOETUj9dwzbiU882hfG0oP/vkQ2jdvmNRms1X50yByZCHic/PYvDzJLEvLubiEC4vlElTbnBLE7btE7s/Ui9DrdZgEW3/ZLVi/hsfsBzLL0x+ErF14q8LZY+mTNq7R7O//+5OmDDpBcTVrc+hXMr7pKod5hMop6dZceFiPqKjFSxAIixMiZzcAug0ajgcVuTm2ZCVWYjY2CAkp5gZlAUp5cYQEBmpQmamiUGaEhVxKJf+EuJQvjaUyQXu+61f4+MvfgAljyeb8u2d7mQ2W9q6afT4/zIbLWmur8ychFcWrcDlpMTrQo62gnpv2Wv4fPMuHPv7QJFL3PVsytu+/RLL35iPzzb9DKfoxJC7OrD8yKtWLEGbdh3Zoh8t1E14bCj6DxqG52bOx7292+G/L8xn9myPTZm2jqKHyPhnpzPNn9p79P4+2PHnKaSnpnAol/5WqVJH+gTK2dk2pKQUIiRYCq1OyRbwWGY3vQJOB0UGgkW/qZRSnD1bwKBM6T7JrYwS8mRm5rOMa5TMPjyC7zRS2iuIQ/naUCa77fMTR+Hg3t2Ijq2DTnf0REZ6Kl57axXzviBbbmrKZaZ9kt2ZzBo30pRpT72WAPAfAAAER0lEQVT77+7MAPvu6g03hTL527/x6ixs+mItyKWSvC/GTHgOB/buxpSJo1hqgFvb3IY+d9+Lac+OxsJlq0FudwTtSdPmMm3a46fs8b7IzcmGUqVm3hm0f+CN+lva66c8x3HzRXmkd+NzfQJl8sbIzCS3NyfbJJVswjLZ1e5haan5LCERpd6MilSxi5xSd5IXh1JJLl6BuZ16xYm/fDVzKJdPfvzsskvA11AOJO+L6yW4dzgckMvlePrpp7F06dIi4W3cuBGrV68G/e+L4hMoezpiMNhYLgpKWkRpOK8sBG/KhUGmCrncHfVHS4W0+Ofewbpy/Xx9IUB/1sGh7E/p1+y2fQ1lf/kpX2sWbwTloKAgFnCyY8cONGvWjJ3ucyi73JERvHAJ+FQCle2n7NPO88puKgFfQ9lbTdmbhES+2nVk8uTJ0Ov1ePPNN7FhwwZQPmUO5ZteKvyAQJEAh3KgzETF9MPXUPa2l6VN3enLXUfIfEFvp1arFW3btmX5lGkrKK4pezt7/Hi/SIBD2S9ir7RG/Q3l0m6c6stdRwjKKpUK9P/PP/+MJ554AqSxb9261bc2ZW6+qLTruEY1xKFcvafb31Am6ZZ2Oyhf7TpSHMrU/tChQ3H77bejcePGHMrV+3KvHqPjUK4e83i9UVSljVM9YyjvriNXQpns4B06dMC8efOwZcsW33lfcE25et88/hodh7K/JF857VYVTdmXu47QHpQe84VHyjNmzMD69evRokULDuXKufR4K2WVAIdyWSVXNc7zN5RLu3GqL3cdWbdu3VVQzs/PZ+aL2267jUO5aly6NbeXHMrVe+79DeXSel/caBYCcdcR6q+Emy+q983jr9GdTzFg/Y/nMLRPK391gbdbgRI4k5iJlPRsjBnYvAJbuX7V3vgpX6+WQExwz6Hsl8upZjRaYLZj9so9GDusc80YcA0b5e7DFxGul2JAp/gqO3IO5So7dbzjZZXA658dQJumdVEvOrSsVfDzAlQCn28/iOE9G6JhXEiA9rDqdoubL6ru3AV8z3f9ncJyF/fv6s4RwEv1kMD5y9k4eOISpj3cvnoMKMBGwaEcYBNS3brz6tp9aNYgBk0TalW3odXI8ThFEeu3H8SgLvXRulFkjZRBRQ+aQ7miJVzD67+QasQbnx/AwG7NER8TVsOlUfWHv23XccSEqXF/j4ZVfzABOgIO5QCdmOrUraMXsrFq8zF0vDUebZrEVqeh1ZixZOTkY9eBc6hbS4eHet9SY8btj4FyKPtD6jWwzbTsAnz1yznkGK1oHF8LdaJDEKJXs93NeQk8CVA+30KzDWlZJpy/nAXyS76nczy6tuIP1YqeLQ7lipYwr7+EBE5fysX+05k4ezkPOUYLHE6RSygAJUDbTWjVCsRF6dAyIRydWkRDLuMP0MqYKg7lypAyb4NLgEuAS6CUEuBQLqWg+GFcAlwCXAKVIYH/B4Mi5U8+HB8VAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "pAGj1-ngDdSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This problem is a supervised classification task, which is conceptually very similar to the audio digit classification already addressed in Lab 2 (the difference is that now we have speaker identities instead of digits in the output).\n",
        "\n",
        "We will work on a small portion of the TIMIT dataset that contains 26 different speakers.\n",
        "\n",
        "\n",
        "**Run the code below** to download and unzip the dataset."
      ],
      "metadata": {
        "id": "9AoECpR2DiCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget -O TIMIT_tiny.zip  https://www.dropbox.com/scl/fi/7t7fi0t4cv424p7zem46g/TIMIT_tiny.zip?rlkey=efh571iyya5sb7w1kvk2xfi9h&dl=0"
      ],
      "metadata": {
        "id": "nFUbhGNStq7w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the code below** to unzip the dataset."
      ],
      "metadata": {
        "id": "H5iasjiuDdPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/TIMIT_tiny.zip -d data"
      ],
      "metadata": {
        "id": "ErE8ni7PuCfR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the code below to install speechbrain**."
      ],
      "metadata": {
        "id": "TEHnO0XYuOOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Installing SpeechBrain via pip\n",
        "BRANCH = 'develop'\n",
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/speechbrain/speechbrain/"
      ],
      "metadata": {
        "id": "GJSRH2aBuiFL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 1: Data Preparation**\n",
        "\n",
        "If you inspect the data stored in `/content/data` you will see 26 folders. Each folder contains the audio signals recorded for a single speaker. You can see different types of files in each folder. For this lab, you only need to consider the \".wav\" ones. The name of each file (e.g., `si475.wav`) is a sentence identifier (`si475`). Each signal is sampled at 16 kHz.\n",
        "\n",
        "**Write the code for preparing the JSON data-manifest files**. You have to split the dataset into train, validation, and test sets. Always use the sentence 'sa1.wav' (available for each speaker) for validation. Use the sentence 'sa2.wav' (available for each speaker) for testing. Use all the other sentences for training.\n",
        "\n",
        "You have to create 3 JSON files:\n",
        "- 'train.json'\n",
        "- 'valid.json'\n",
        "- 'test.json'\n",
        "\n",
        "They should be formatted in the following way:\n",
        "\n",
        "\n",
        "**train.json**\n",
        "```\n",
        "{\n",
        "  \"mpgl0_si469\": {\n",
        "    \"path\": \"data/mpgl0/si469.wav\",\n",
        "    \"length\": 2.88,\n",
        "    \"spk\": \"mpgl0\"\n",
        "  },\n",
        "  \"mpgl0_si1729\": {\n",
        "    \"path\": \"data/mpgl0/si1729.wav\",\n",
        "    \"length\": 3.5904375,\n",
        "    \"spk\": \"mpgl0\"\n",
        "  },\n",
        "  \"mpgl0_si1099\": {\n",
        "    \"path\": \"data/mpgl0/si1099.wav\",\n",
        "    \"length\": 2.86725,\n",
        "    \"spk\": \"mpgl0\"\n",
        "  },\n",
        "....\n",
        "\n",
        "```\n",
        "\n",
        "**valid.json**\n",
        "```\n",
        "{\n",
        "  \"mpgl0_sa1\": {\n",
        "    \"path\": \"data/mpgl0/sa1.wav\",\n",
        "    \"length\": 3.6288125,\n",
        "    \"spk\": \"mpgl0\"\n",
        "  },\n",
        "  \"mtmr0_sa1\": {\n",
        "    \"path\": \"data/mtmr0/sa1.wav\",\n",
        "    \"length\": 3.18725,\n",
        "    \"spk\": \"mtmr0\"\n",
        "  },\n",
        "  \"mwvw0_sa1\": {\n",
        "    \"path\": \"data/mwvw0/sa1.wav\",\n",
        "    \"length\": 3.161625,\n",
        "    \"spk\": \"mwvw0\"\n",
        "  },\n",
        "....\n",
        "```\n",
        "\n",
        "**test.json**\n",
        "\n",
        "```\n",
        "{\n",
        "  \"mpgl0_sa2\": {\n",
        "    \"path\": \"data/mpgl0/sa2.wav\",\n",
        "    \"length\": 3.02725,\n",
        "    \"spk\": \"mpgl0\"\n",
        "  },\n",
        "  \"mtmr0_sa2\": {\n",
        "    \"path\": \"data/mtmr0/sa2.wav\",\n",
        "    \"length\": 2.624,\n",
        "    \"spk\": \"mtmr0\"\n",
        "  },\n",
        "  \"mwvw0_sa2\": {\n",
        "    \"path\": \"data/mwvw0/sa2.wav\",\n",
        "    \"length\": 2.5088125,\n",
        "    \"spk\": \"mwvw0\"\n",
        "  },\n",
        "\n",
        "```\n",
        "\n",
        "If everything is fine, you should have 208 files for training, 26 for validation, and 26 for testing.\n",
        "\n",
        "**Suggestions:**\n",
        "- Use the get_all_files in speechbrain.utils.data_utils to get a list of all the files with the wav extension.\n",
        "- You can get the number of samples of each wave with torchaudio.info. You have to compute the duration in seconds by diving it for the sampling frequency."
      ],
      "metadata": {
        "id": "-rK3VCFkEyRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your code here:**"
      ],
      "metadata": {
        "id": "gi61MzNjMe53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxXTPKTKmRzo",
        "outputId": "d6a6f300-f6af-411b-a992-1cfff328b8b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import torchaudio\n",
        "from speechbrain.utils.data_utils import get_all_files\n",
        "\n",
        "# Your code here\n",
        "# train_data = get_all_files(\"/content/data\", exclude_and=['sa1.wav', 'sa2.wav'], match_and=['.wav'])\n",
        "\n",
        "\n",
        "def create_json(data, dir_name):\n",
        "  extracted_data = {}\n",
        "\n",
        "  for file_path in data:\n",
        "    spk = file_path.split('/')[1]\n",
        "    sa_number = file_path.split('/')[-1].split('.')[0]\n",
        "    info = torchaudio.info(file_path)\n",
        "\n",
        "    # Compute duration in seconds\n",
        "    duration_sec = info.num_frames / info.sample_rate\n",
        "\n",
        "    # Construct dictionary entry\n",
        "    key = f\"{spk}_{sa_number}\"\n",
        "    extracted_data[key] = {\n",
        "        \"wav\": file_path,\n",
        "        \"length\": duration_sec,\n",
        "        \"spk\": spk\n",
        "    }\n",
        "\n",
        "  # Write extracted data to a JSON file\n",
        "  with open(f\"{dir_name}.json\", \"w\") as json_file:\n",
        "      json.dump(extracted_data, json_file, indent=4)\n",
        "\n",
        "train_data = get_all_files(\"data\", match_and=['.wav'])\n",
        "train_data = [file for file in train_data if os.path.basename(file) not in ['sa1.wav', 'sa2.wav']]\n",
        "\n",
        "test_data = get_all_files(\"data\", match_and=['sa2.wav'])\n",
        "\n",
        "valid_data = get_all_files(\"data\", match_and=['sa1.wav'])\n",
        "\n",
        "print(\"Train Data -> \", len(train_data))\n",
        "print(\"Test Data -> \", len(test_data))\n",
        "print(\"Valid Data -> \", len(valid_data))\n",
        "\n",
        "create_json(train_data, \"train\")\n",
        "create_json(test_data, \"test\")\n",
        "create_json(valid_data, \"valid\")"
      ],
      "metadata": {
        "id": "q200dslGuOpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61299e83-d3b8-4ead-a66e-8e55e382d27f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data ->  208\n",
            "Test Data ->  26\n",
            "Valid Data ->  26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 2: Speaker Identification with FBANKs and Xvectors**\n",
        "\n",
        "You have to implement the following model:\n",
        "\n"
      ],
      "metadata": {
        "id": "ChYSbsxuJtRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![pictures-Page-1.drawio (6).png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "eU8QjhbVLQeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Suggestion:** You can copy-and-paste the code from the previous labs solving similar classification problems. You only need to do the little modifications to the hyperparameter and train.py files needed to implement the system in the figure."
      ],
      "metadata": {
        "id": "2ub2g7UKLiVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write the code for the hyperparameters**:"
      ],
      "metadata": {
        "id": "hmdPGYXQMyMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hparams_xvector_fbanks.yaml\n",
        "\n",
        "# Your code here\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 1986\n",
        "__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "output_folder: !ref ./results/TIMIT_tiny/Xvector/FBanks/<seed>\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "# Path where data manifest files are stored\n",
        "train_annotation: train.json\n",
        "valid_annotation: valid.json\n",
        "test_annotation: test.json\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
        "    metric: !name:speechbrain.nnet.losses.classification_error\n",
        "        reduction: batch\n",
        "\n",
        "# Feature parameters\n",
        "n_mels: 40\n",
        "\n",
        "# Training Parameters\n",
        "sample_rate: 16000\n",
        "number_of_epochs: 20\n",
        "batch_size: 16\n",
        "lr_start: 0.001\n",
        "lr_final: 0.0001\n",
        "n_classes: 26\n",
        "emb_dim: 128 # dimensionality of the embeddings\n",
        "dataloader_options:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Feature extraction\n",
        "compute_features: !new:speechbrain.lobes.features.Fbank\n",
        "    n_mels: !ref <n_mels>\n",
        "\n",
        "# Mean and std normalization of the input features\n",
        "mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
        "    norm_type: global\n",
        "\n",
        "# Embedding model: from variable size digits gets a fixed size embedding vector\n",
        "embedding_model: !new:speechbrain.lobes.models.Xvector.Xvector\n",
        "    in_channels: !ref <n_mels>\n",
        "    activation: !name:torch.nn.LeakyReLU\n",
        "    tdnn_blocks: 3\n",
        "    tdnn_channels: [128, 128, 128]\n",
        "    tdnn_kernel_sizes: [5, 3, 1]\n",
        "    tdnn_dilations: [1, 3, 1]\n",
        "    lin_neurons: !ref <emb_dim>\n",
        "\n",
        "# Clasifier applied on top of the embeddings\n",
        "classifier: !new:speechbrain.lobes.models.Xvector.Classifier\n",
        "    input_shape: [null, null, !ref <emb_dim>]\n",
        "    activation: !name:torch.nn.LeakyReLU\n",
        "    lin_blocks: 1\n",
        "    lin_neurons: !ref <emb_dim>\n",
        "    out_neurons: !ref <n_classes>\n",
        "\n",
        "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
        "# which is saved by the Checkpointer so that training can be resumed\n",
        "# if it gets interrupted at any point.\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
        "# device, as well as having train()/eval() called on them by the Brain class.\n",
        "modules:\n",
        "    compute_features: !ref <compute_features>\n",
        "    mean_var_norm: !ref <mean_var_norm>\n",
        "    embedding_model: !ref <embedding_model>\n",
        "    classifier: !ref <classifier>\n",
        "\n",
        "# This optimizer will be constructed by the Brain class after all parameters\n",
        "# are moved to the correct device. Then it will be added to the checkpointer.\n",
        "opt_class: !name:torch.optim.Adam\n",
        "    lr: !ref <lr_start>\n",
        "\n",
        "# This function manages learning rate annealing over the epochs.\n",
        "# We here use the simple lr annealing method that linearly decreases\n",
        "# the lr from the initial value to the final one.\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
        "    initial_value: !ref <lr_start>\n",
        "    final_value: !ref <lr_final>\n",
        "    epoch_count: !ref <number_of_epochs>\n",
        "\n",
        "# This object is used for saving the state of training both so that it\n",
        "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
        "# can be later loaded for evaluation or inference.\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        embedding_model: !ref <embedding_model>\n",
        "        classifier: !ref <classifier>\n",
        "        normalizer: !ref <mean_var_norm>\n",
        "        counter: !ref <epoch_counter>"
      ],
      "metadata": {
        "id": "iehjUAG21SLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505b4a42-5869-4761-c4b9-4a7e7633e694"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hparams_xvector_fbanks.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write the code for the training script**:"
      ],
      "metadata": {
        "id": "VwPQS7CCM_dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train.py\n",
        "\n",
        "# Your code here\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "\"Recipe for training a spk classification system.\"\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torchaudio\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "\n",
        "\n",
        "# Brain class for speech enhancement training\n",
        "class DigitBrain(sb.Brain):\n",
        "    \"\"\"Class that manages the training loop. See speechbrain.core.Brain.\"\"\"\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Runs all the computations that transforms the input into the\n",
        "        output probabilities over the N classes.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "        Returns\n",
        "        -------\n",
        "        predictions : Tensor\n",
        "            Tensor that contains the posterior probabilities over the N classes.\n",
        "        \"\"\"\n",
        "        # Your code here. Aim for 7-8 lines\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, lens = batch.sig\n",
        "        feats = self.modules.compute_features(wavs)\n",
        "        feats = self.modules.mean_var_norm(feats, lens)\n",
        "        embeddings = self.modules.embedding_model(feats, lens)\n",
        "        predictions = self.modules.classifier(embeddings)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss given the predicted and targeted outputs.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        predictions : tensor\n",
        "            The output tensor from `compute_forward`.\n",
        "        batch : PaddedBatch\n",
        "            This batch object contains all the relevant tensors for computation.\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            A one-element tensor used for backpropagating the gradient.\n",
        "        \"\"\"\n",
        "\n",
        "        # Your code here. Aim for 7-8 lines\n",
        "        _, lens = batch['sig']\n",
        "        digit_encoded = batch[\"digit_encoded\"].data\n",
        "\n",
        "        loss = sb.nnet.losses.nll_loss(predictions, digit_encoded, lens)\n",
        "        self.loss_metric.append(\n",
        "            batch.id, predictions, digit_encoded, lens, reduction=\"batch\"\n",
        "        )\n",
        "\n",
        "        # Compute classification error at test time\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.error_metrics.append(batch.id, predictions, digit_encoded, lens)\n",
        "        return loss\n",
        "\n",
        "    def on_stage_start(self, stage, epoch=None):\n",
        "        \"\"\"Gets called at the beginning of each epoch.\n",
        "        Arguments\n",
        "        ---------\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, or sb.Stage.TEST.\n",
        "        epoch : int\n",
        "            The currently-starting epoch. This is passed\n",
        "            `None` during the test stage.\n",
        "        \"\"\"\n",
        "\n",
        "        # Set up statistics trackers for this stage\n",
        "        self.loss_metric = sb.utils.metric_stats.MetricStats(\n",
        "            metric=sb.nnet.losses.nll_loss\n",
        "        )\n",
        "\n",
        "        # Set up evaluation-only statistics trackers\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.error_metrics = self.hparams.error_stats()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch=None):\n",
        "        \"\"\"Gets called at the end of an epoch.\n",
        "        Arguments\n",
        "        ---------\n",
        "        stage : sb.Stage\n",
        "            One of sb.Stage.TRAIN, sb.Stage.VALID, sb.Stage.TEST\n",
        "        stage_loss : float\n",
        "            The average loss for all of the data processed in this stage.\n",
        "        epoch : int\n",
        "            The currently-starting epoch. This is passed\n",
        "            `None` during the test stage.\n",
        "        \"\"\"\n",
        "\n",
        "        # Store the train loss until the validation stage.\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_loss = stage_loss\n",
        "\n",
        "        # Summarize the statistics from the stage for record-keeping.\n",
        "        else:\n",
        "            stats = {\n",
        "                \"loss\": stage_loss,\n",
        "                \"error\": self.error_metrics.summarize(\"average\"),\n",
        "            }\n",
        "\n",
        "        # At the end of validation...\n",
        "        if stage == sb.Stage.VALID:\n",
        "\n",
        "            old_lr, new_lr = self.hparams.lr_annealing(epoch)\n",
        "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "\n",
        "            # The train_logger writes a summary to stdout and to the logfile.\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats={\"loss\": self.train_loss},\n",
        "                valid_stats=stats,\n",
        "            )\n",
        "\n",
        "            # Save the current checkpoint and delete previous checkpoints,\n",
        "            self.checkpointer.save_and_keep_only(meta=stats, min_keys=[\"error\"])\n",
        "\n",
        "        # We also write statistics about test data to stdout and to the logfile.\n",
        "        if stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                {\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stats,\n",
        "            )\n",
        "\n",
        "\n",
        "def dataio_prep(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "    We expect `prepare_mini_librispeech` to have been called before this,\n",
        "    so that the `train.json`, `valid.json`,  and `valid.json` manifest files\n",
        "    are available.\n",
        "    Arguments\n",
        "    ---------\n",
        "    hparams : dict\n",
        "        This dictionary is loaded from the `train.yaml` file, and it includes\n",
        "        all the hyperparameters needed for dataset construction and loading.\n",
        "    Returns\n",
        "    -------\n",
        "    datasets : dict\n",
        "        Contains two keys, \"train\" and \"valid\" that correspond\n",
        "        to the appropriate DynamicItemDataset object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialization of the label encoder. The label encoder assigns to each\n",
        "    # of the observed label a unique index (e.g, 'digit0': 0, 'digit1': 1, ..)\n",
        "    label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
        "    print(label_encoder)\n",
        "\n",
        "    # Define audio pipeline\n",
        "    @sb.utils.data_pipeline.takes(\"wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav):\n",
        "        \"\"\"Load the signal, and pass it and its length to the corruption class.\n",
        "        This is done on the CPU in the `collate_fn`.\"\"\"\n",
        "        sig, fs = torchaudio.load(wav)\n",
        "\n",
        "        # Resampling\n",
        "        sig = torchaudio.functional.resample(sig, fs, 16000).squeeze(0)\n",
        "        return sig\n",
        "\n",
        "    # Define label pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"spk\")\n",
        "    @sb.utils.data_pipeline.provides(\"spk\", \"digit_encoded\")\n",
        "    def label_pipeline(spk):\n",
        "        \"\"\"Defines the pipeline to process the spk labels.\n",
        "        Note that we have to assign a different integer to each class\n",
        "        through the label encoder.\n",
        "        \"\"\"\n",
        "        yield spk\n",
        "        digit_encoded = label_encoder.encode_label_torch(spk)\n",
        "        yield digit_encoded\n",
        "\n",
        "    # Define datasets. We also connect the dataset with the data processing\n",
        "    # functions defined above.\n",
        "    datasets = {}\n",
        "    data_info = {\n",
        "        \"train\": hparams[\"train_annotation\"],\n",
        "        \"valid\": hparams[\"valid_annotation\"],\n",
        "        \"test\": hparams[\"test_annotation\"],\n",
        "    }\n",
        "    hparams[\"dataloader_options\"][\"shuffle\"] = True\n",
        "    for dataset in data_info:\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
        "            json_path=data_info[dataset],\n",
        "            dynamic_items=[audio_pipeline, label_pipeline],\n",
        "            output_keys=[\"id\", \"sig\", \"digit_encoded\"],\n",
        "        )\n",
        "\n",
        "    # Load or compute the label encoder (with multi-GPU DDP support)\n",
        "    # Please, take a look into the lab_enc_file to see the label to index\n",
        "    # mapping.\n",
        "    lab_enc_file = os.path.join(hparams[\"save_folder\"], \"label_encoder.txt\")\n",
        "    label_encoder.load_or_create(\n",
        "        path=lab_enc_file,\n",
        "        from_didatasets=[datasets[\"train\"]],\n",
        "        output_key=\"spk\",\n",
        "    )\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "# Recipe begins!\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Reading command line arguments.\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "\n",
        "    # Load hyperparameters file with command-line overrides.\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin,  overrides)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # Create dataset objects \"train\", \"valid\", and \"test\".\n",
        "    datasets = dataio_prep(hparams)\n",
        "\n",
        "    # Initialize the Brain object to prepare for mask training.\n",
        "    digit_brain = DigitBrain(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"opt_class\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    # The `fit()` method iterates the training loop, calling the methods\n",
        "    # necessary to update the parameters of the model. Since all objects\n",
        "    # with changing state are managed by the Checkpointer, training can be\n",
        "    # stopped at any point, and will be resumed on next call.\n",
        "    digit_brain.fit(\n",
        "        epoch_counter=digit_brain.hparams.epoch_counter,\n",
        "        train_set=datasets[\"train\"],\n",
        "        valid_set=datasets[\"valid\"],\n",
        "        train_loader_kwargs=hparams[\"dataloader_options\"],\n",
        "        valid_loader_kwargs=hparams[\"dataloader_options\"],\n",
        "    )\n",
        "\n",
        "    # Load the best checkpoint for evaluation\n",
        "    test_stats = digit_brain.evaluate(\n",
        "        test_set=datasets[\"test\"],\n",
        "        min_key=\"error\",\n",
        "        test_loader_kwargs=hparams[\"dataloader_options\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "GfnCP4cm15nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3edbc02-e357-41d5-b465-98c483121f70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the code below to train your model.**"
      ],
      "metadata": {
        "id": "4NHq93VtQzuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the output folder to start training from scratch\n",
        "# (and not from a previous checkpoint).\n",
        "!rm -rf /content/results/TIMIT_tiny/Xvector/FBANKs/1986\n",
        "\n",
        "# Run Training\n",
        "!python train.py hparams_xvector_fbanks.yaml --device='cpu'"
      ],
      "metadata": {
        "id": "jzRhkOS534FC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcac6fd-cbf5-41dc-ca32-793bf7a530b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: ./results/TIMIT_tiny/Xvector/FBanks/1986\n",
            "<speechbrain.dataio.encoder.CategoricalEncoder object at 0x780de27ed090>\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - 145.6k trainable parameters in DigitBrain\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "100% 13/13 [00:04<00:00,  2.70it/s, train_loss=2.69]\n",
            "100% 2/2 [00:00<00:00,  6.59it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.001 to 0.00095\n",
            "speechbrain.utils.train_logger - Epoch: 1, lr: 1.00e-03 - train loss: 2.69 - valid loss: 3.20, valid error: 9.23e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-33+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 13/13 [00:03<00:00,  3.50it/s, train_loss=1.67]\n",
            "100% 2/2 [00:00<00:00,  7.04it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00095 to 0.00091\n",
            "speechbrain.utils.train_logger - Epoch: 2, lr: 9.53e-04 - train loss: 1.67 - valid loss: 2.74, valid error: 6.54e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-37+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-33+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "100% 13/13 [00:03<00:00,  3.86it/s, train_loss=1.12]\n",
            "100% 2/2 [00:00<00:00, 10.68it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00091 to 0.00086\n",
            "speechbrain.utils.train_logger - Epoch: 3, lr: 9.05e-04 - train loss: 1.12 - valid loss: 1.75, valid error: 2.31e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-40+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-37+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "100% 13/13 [00:03<00:00,  3.87it/s, train_loss=0.777]\n",
            "100% 2/2 [00:00<00:00,  9.77it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00086 to 0.00081\n",
            "speechbrain.utils.train_logger - Epoch: 4, lr: 8.58e-04 - train loss: 7.77e-01 - valid loss: 1.29, valid error: 1.92e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-44+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-40+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "100% 13/13 [00:04<00:00,  3.14it/s, train_loss=0.532]\n",
            "100% 2/2 [00:00<00:00, 10.25it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00081 to 0.00076\n",
            "speechbrain.utils.train_logger - Epoch: 5, lr: 8.11e-04 - train loss: 5.32e-01 - valid loss: 8.90e-01, valid error: 7.69e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-48+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n",
            "100% 13/13 [00:03<00:00,  3.97it/s, train_loss=0.351]\n",
            "100% 2/2 [00:00<00:00, 10.57it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00076 to 0.00072\n",
            "speechbrain.utils.train_logger - Epoch: 6, lr: 7.63e-04 - train loss: 3.51e-01 - valid loss: 4.97e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-52+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n",
            "100% 13/13 [00:03<00:00,  4.10it/s, train_loss=0.287]\n",
            "100% 2/2 [00:00<00:00, 10.45it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00072 to 0.00067\n",
            "speechbrain.utils.train_logger - Epoch: 7, lr: 7.16e-04 - train loss: 2.87e-01 - valid loss: 4.35e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-55+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n",
            "100% 13/13 [00:04<00:00,  3.24it/s, train_loss=0.187]\n",
            "100% 2/2 [00:00<00:00,  9.72it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00067 to 0.00062\n",
            "speechbrain.utils.train_logger - Epoch: 8, lr: 6.68e-04 - train loss: 1.87e-01 - valid loss: 3.54e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-00+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-55+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n",
            "100% 13/13 [00:03<00:00,  4.02it/s, train_loss=0.165]\n",
            "100% 2/2 [00:00<00:00, 10.69it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00062 to 0.00057\n",
            "speechbrain.utils.train_logger - Epoch: 9, lr: 6.21e-04 - train loss: 1.65e-01 - valid loss: 2.74e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-03+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-00+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-45-52+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n",
            "100% 13/13 [00:03<00:00,  4.00it/s, train_loss=0.102]\n",
            "100% 2/2 [00:00<00:00, 10.76it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00057 to 0.00053\n",
            "speechbrain.utils.train_logger - Epoch: 10, lr: 5.74e-04 - train loss: 1.02e-01 - valid loss: 1.92e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-06+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n",
            "100% 13/13 [00:03<00:00,  3.76it/s, train_loss=0.0923]\n",
            "100% 2/2 [00:00<00:00,  7.23it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00053 to 0.00048\n",
            "speechbrain.utils.train_logger - Epoch: 11, lr: 5.26e-04 - train loss: 9.23e-02 - valid loss: 1.46e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-10+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-06+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-03+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n",
            "100% 13/13 [00:03<00:00,  3.44it/s, train_loss=0.0747]\n",
            "100% 2/2 [00:00<00:00, 10.55it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00048 to 0.00043\n",
            "speechbrain.utils.train_logger - Epoch: 12, lr: 4.79e-04 - train loss: 7.47e-02 - valid loss: 1.46e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-14+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-10+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n",
            "100% 13/13 [00:03<00:00,  4.14it/s, train_loss=0.0756]\n",
            "100% 2/2 [00:00<00:00, 10.58it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00043 to 0.00038\n",
            "speechbrain.utils.train_logger - Epoch: 13, lr: 4.32e-04 - train loss: 7.56e-02 - valid loss: 1.47e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-18+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-14+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n",
            "100% 13/13 [00:03<00:00,  4.09it/s, train_loss=0.0595]\n",
            "100% 2/2 [00:00<00:00, 10.33it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00038 to 0.00034\n",
            "speechbrain.utils.train_logger - Epoch: 14, lr: 3.84e-04 - train loss: 5.95e-02 - valid loss: 1.46e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-21+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n",
            "100% 13/13 [00:04<00:00,  3.21it/s, train_loss=0.0569]\n",
            "100% 2/2 [00:00<00:00, 10.76it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00034 to 0.00029\n",
            "speechbrain.utils.train_logger - Epoch: 15, lr: 3.37e-04 - train loss: 5.69e-02 - valid loss: 1.05e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-25+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-18+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-21+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n",
            "100% 13/13 [00:03<00:00,  4.03it/s, train_loss=0.0514]\n",
            "100% 2/2 [00:00<00:00, 10.38it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00029 to 0.00024\n",
            "speechbrain.utils.train_logger - Epoch: 16, lr: 2.89e-04 - train loss: 5.14e-02 - valid loss: 1.20e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-29+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n",
            "100% 13/13 [00:03<00:00,  4.04it/s, train_loss=0.0616]\n",
            "100% 2/2 [00:00<00:00, 10.30it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00024 to 0.00019\n",
            "speechbrain.utils.train_logger - Epoch: 17, lr: 2.42e-04 - train loss: 6.16e-02 - valid loss: 1.11e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-32+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-25+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-29+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n",
            "100% 13/13 [00:03<00:00,  3.28it/s, train_loss=0.0593]\n",
            "100% 2/2 [00:00<00:00,  7.09it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00019 to 0.00015\n",
            "speechbrain.utils.train_logger - Epoch: 18, lr: 1.95e-04 - train loss: 5.93e-02 - valid loss: 1.05e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-37+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n",
            "100% 13/13 [00:03<00:00,  4.02it/s, train_loss=0.0426]\n",
            "100% 2/2 [00:00<00:00, 10.67it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00015 to 0.0001\n",
            "speechbrain.utils.train_logger - Epoch: 19, lr: 1.47e-04 - train loss: 4.26e-02 - valid loss: 1.00e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-40+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-37+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n",
            "100% 13/13 [00:03<00:00,  3.45it/s, train_loss=0.0484]\n",
            "100% 2/2 [00:00<00:00,  4.89it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 20, lr: 1.00e-04 - train loss: 4.84e-02 - valid loss: 1.00e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-45+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/TIMIT_tiny/Xvector/FBanks/1986/save/CKPT+2024-02-23+21-46-40+00\n",
            "100% 2/2 [00:00<00:00, 12.80it/s]\n",
            "speechbrain.utils.train_logger - Epoch loaded: 19 - test loss: 6.66e-02, test error: 0.00e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have to tweak the hyperparameter (e.g., batch size, learning rate) a bit to improve the performance. Do at least 20 epochs, If everything goes well, you should see a training curve similar to this one:\n",
        "\n",
        "\n",
        "```\n",
        "Epoch: 1, lr: 1.00e-03 - train loss: 2.82 - valid loss: 3.25, valid error: 9.62e-01\n",
        "Epoch: 2, lr: 9.53e-04 - train loss: 1.92 - valid loss: 2.90, valid error: 9.62e-01\n",
        "Epoch: 3, lr: 9.05e-04 - train loss: 1.39 - valid loss: 1.83, valid error: 3.46e-01\n",
        "Epoch: 4, lr: 8.58e-04 - train loss: 9.68e-01 - valid loss: 1.50, valid error: 4.62e-01\n",
        "Epoch: 5, lr: 8.11e-04 - train loss: 6.71e-01 - valid loss: 9.79e-01, valid error: 7.69e-02\n",
        "Epoch: 6, lr: 7.63e-04 - train loss: 5.14e-01 - valid loss: 9.43e-01, valid error: 1.92e-01\n",
        "Epoch: 7, lr: 7.16e-04 - train loss: 3.93e-01 - valid loss: 6.59e-01, valid error: 3.85e-02\n",
        "Epoch: 8, lr: 6.68e-04 - train loss: 2.63e-01 - valid loss: 3.22e-01, valid error: 0.00e+00\n",
        "Epoch: 9, lr: 6.21e-04 - train loss: 2.30e-01 - valid loss: 4.71e-01, valid error: 7.69e-02\n",
        "Epoch: 10, lr: 5.74e-04 - train loss: 1.56e-01 - valid loss: 2.67e-01, valid error: 3.85e-02\n",
        "Epoch: 11, lr: 5.26e-04 - train loss: 1.25e-01 - valid loss: 1.58e-01, valid error: 0.00e+00\n",
        "Epoch: 12, lr: 4.79e-04 - train loss: 1.15e-01 - valid loss: 2.09e-01, valid error: 3.85e-02\n",
        "Epoch: 13, lr: 4.32e-04 - train loss: 9.57e-02 - valid loss: 1.60e-01, valid error: 0.00e+00\n",
        "Epoch: 14, lr: 3.84e-04 - train loss: 7.75e-02 - valid loss: 1.56e-01, valid error: 0.00e+00\n",
        "Epoch: 15, lr: 3.37e-04 - train loss: 7.18e-02 - valid loss: 1.42e-01, valid error: 0.00e+00\n",
        "Epoch: 16, lr: 2.89e-04 - train loss: 7.01e-02 - valid loss: 1.06e-01, valid error: 0.00e+00\n",
        "Epoch: 17, lr: 2.42e-04 - train loss: 7.01e-02 - valid loss: 1.22e-01, valid error: 0.00e+00\n",
        "Epoch: 18, lr: 1.95e-04 - train loss: 7.55e-02 - valid loss: 1.50e-01, valid error: 3.85e-02\n",
        "Epoch: 19, lr: 1.47e-04 - train loss: 5.16e-02 - valid loss: 1.21e-01, valid error: 3.85e-02\n",
        "Epoch: 20, lr: 1.00e-04 - train loss: 5.97e-02 - valid loss: 1.12e-01, valid error: 3.85e-02\n",
        "Epoch loaded: 17 - test loss: 9.28e-02, test error: 0.00e+00\n",
        "\n",
        "```\n",
        "\n",
        "As you can see, you should be able to obtain a 0% error on both training and validation. If this is not the case, run the experiment again with a different set of hyperparameters. Note that we are using a tiny dataset and it is normal to see some significant performance variations after running the code multiple times with different random seeds.\n",
        "\n",
        "\n",
        "It might be surprising to see a 0% error on both validation and test. On the other hand, for humans, it might be hard to detect which speaker is speaking among 26 candidates after listening for just a few minutes their voices. For a neural network, instead, this task is very easy. Even on large datasets containing noise recordings and thousands of speakers, a good neural network can identify speakers with 98-99% accuracy.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fHRdQ9oKNO9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 3: Speaker Identification with MFCCs and Xvectors**\n",
        "\n",
        "in this exercise, you have to run the same system as exercise 2, but with different speech features in the input.\n",
        "\n",
        "This time, you should feed the system with mel frequency cepstral coefficients (MFCCs). You have to compute them with `speechbrain.lobes.features.MFCC` (please take a look at the documentation [here](https://speechbrain.readthedocs.io/en/latest/API/speechbrain.lobes.features.html). For this exercise, do not augment the features with the context and with the delta coefficients. You can compute 20 MFFCs.\n",
        "\n",
        "Modify the hparam file to implement the MFCC-based speaker identification system. Note that you do not need to modify the train.py script as well.\n",
        "\n",
        "**Your code here**:"
      ],
      "metadata": {
        "id": "Vs8KGFNTO7cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hparams_xvector_mfccs.yaml\n",
        "\n",
        "# Your code here\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 1986\n",
        "__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "output_folder: !ref ./results/TIMIT_tiny/Xvector/MFCCs/<seed>\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "# Path where data manifest files are stored\n",
        "train_annotation: train.json\n",
        "valid_annotation: valid.json\n",
        "test_annotation: test.json\n",
        "\n",
        "# The train logger writes training statistics to a file, as well as stdout.\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "error_stats: !name:speechbrain.utils.metric_stats.MetricStats\n",
        "    metric: !name:speechbrain.nnet.losses.classification_error\n",
        "        reduction: batch\n",
        "\n",
        "# Feature parameters\n",
        "n_mels: 40\n",
        "\n",
        "# Training Parameters\n",
        "sample_rate: 16000\n",
        "number_of_epochs: 20\n",
        "batch_size: 16\n",
        "lr_start: 0.001\n",
        "lr_final: 0.0001\n",
        "n_classes: 26\n",
        "emb_dim: 128 # dimensionality of the embeddings\n",
        "dataloader_options:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Feature extraction\n",
        "compute_features: !new:speechbrain.lobes.features.Fbank\n",
        "    n_mels: !ref <n_mels>\n",
        "    deltas: False\n",
        "    context: False\n",
        "\n",
        "# Mean and std normalization of the input features\n",
        "mean_var_norm: !new:speechbrain.processing.features.InputNormalization\n",
        "    norm_type: global\n",
        "\n",
        "# Embedding model: from variable size digits gets a fixed size embedding vector\n",
        "embedding_model: !new:speechbrain.lobes.models.Xvector.Xvector\n",
        "    in_channels: !ref <n_mels>\n",
        "    activation: !name:torch.nn.LeakyReLU\n",
        "    tdnn_blocks: 3\n",
        "    tdnn_channels: [128, 128, 128]\n",
        "    tdnn_kernel_sizes: [5, 3, 1]\n",
        "    tdnn_dilations: [1, 3, 1]\n",
        "    lin_neurons: !ref <emb_dim>\n",
        "\n",
        "# Clasifier applied on top of the embeddings\n",
        "classifier: !new:speechbrain.lobes.models.Xvector.Classifier\n",
        "    input_shape: [null, null, !ref <emb_dim>]\n",
        "    activation: !name:torch.nn.LeakyReLU\n",
        "    lin_blocks: 1\n",
        "    lin_neurons: !ref <emb_dim>\n",
        "    out_neurons: !ref <n_classes>\n",
        "\n",
        "# The first object passed to the Brain class is this \"Epoch Counter\"\n",
        "# which is saved by the Checkpointer so that training can be resumed\n",
        "# if it gets interrupted at any point.\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "# Objects in \"modules\" dict will have their parameters moved to the correct\n",
        "# device, as well as having train()/eval() called on them by the Brain class.\n",
        "modules:\n",
        "    compute_features: !ref <compute_features>\n",
        "    mean_var_norm: !ref <mean_var_norm>\n",
        "    embedding_model: !ref <embedding_model>\n",
        "    classifier: !ref <classifier>\n",
        "\n",
        "# This optimizer will be constructed by the Brain class after all parameters\n",
        "# are moved to the correct device. Then it will be added to the checkpointer.\n",
        "opt_class: !name:torch.optim.Adam\n",
        "    lr: !ref <lr_start>\n",
        "\n",
        "# This function manages learning rate annealing over the epochs.\n",
        "# We here use the simple lr annealing method that linearly decreases\n",
        "# the lr from the initial value to the final one.\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler\n",
        "    initial_value: !ref <lr_start>\n",
        "    final_value: !ref <lr_final>\n",
        "    epoch_count: !ref <number_of_epochs>\n",
        "\n",
        "# This object is used for saving the state of training both so that it\n",
        "# can be resumed if it gets interrupted, and also so that the best checkpoint\n",
        "# can be later loaded for evaluation or inference.\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        embedding_model: !ref <embedding_model>\n",
        "        classifier: !ref <classifier>\n",
        "        normalizer: !ref <mean_var_norm>\n",
        "        counter: !ref <epoch_counter>"
      ],
      "metadata": {
        "id": "NgCmjZ6w8IaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23bf6cb-71bf-4a48-9015-d0030bbdcc70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hparams_xvector_mfccs.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the code below to train your model.**"
      ],
      "metadata": {
        "id": "UPH_Qzd8RBY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the output folder to start training from scratch\n",
        "# (and not from a previous checkpoint).\n",
        "!rm -rf ./results/TIMIT_tiny/Xvector/MFCCs/1986\n",
        "\n",
        "# Run Training\n",
        "!python train.py hparams_xvector_mfccs.yaml --device='cpu'"
      ],
      "metadata": {
        "id": "vIjU5aC49C7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c730d91-d603-444c-c61f-87090e4d2589"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: ./results/TIMIT_tiny/Xvector/MFCCs/1986\n",
            "<speechbrain.dataio.encoder.CategoricalEncoder object at 0x7da20f338940>\n",
            "speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - 145.6k trainable parameters in DigitBrain\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "100% 13/13 [00:03<00:00,  3.64it/s, train_loss=2.69]\n",
            "100% 2/2 [00:00<00:00,  7.73it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.001 to 0.00095\n",
            "speechbrain.utils.train_logger - Epoch: 1, lr: 1.00e-03 - train loss: 2.69 - valid loss: 3.20, valid error: 9.23e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-48-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "100% 13/13 [00:03<00:00,  3.30it/s, train_loss=1.67]\n",
            "100% 2/2 [00:00<00:00,  9.74it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00095 to 0.00091\n",
            "speechbrain.utils.train_logger - Epoch: 2, lr: 9.53e-04 - train loss: 1.67 - valid loss: 2.74, valid error: 6.54e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-01+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-48-56+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "100% 13/13 [00:03<00:00,  4.00it/s, train_loss=1.12]\n",
            "100% 2/2 [00:00<00:00, 10.55it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00091 to 0.00086\n",
            "speechbrain.utils.train_logger - Epoch: 3, lr: 9.05e-04 - train loss: 1.12 - valid loss: 1.75, valid error: 2.31e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-04+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-01+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "100% 13/13 [00:03<00:00,  3.95it/s, train_loss=0.777]\n",
            "100% 2/2 [00:00<00:00,  9.73it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00086 to 0.00081\n",
            "speechbrain.utils.train_logger - Epoch: 4, lr: 8.58e-04 - train loss: 7.77e-01 - valid loss: 1.29, valid error: 1.92e-01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-08+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-04+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "100% 13/13 [00:05<00:00,  2.53it/s, train_loss=0.532]\n",
            "100% 2/2 [00:00<00:00, 10.81it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00081 to 0.00076\n",
            "speechbrain.utils.train_logger - Epoch: 5, lr: 8.11e-04 - train loss: 5.32e-01 - valid loss: 8.90e-01, valid error: 7.69e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-13+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-08+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n",
            "100% 13/13 [00:03<00:00,  3.73it/s, train_loss=0.351]\n",
            "100% 2/2 [00:00<00:00, 10.54it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00076 to 0.00072\n",
            "speechbrain.utils.train_logger - Epoch: 6, lr: 7.63e-04 - train loss: 3.51e-01 - valid loss: 4.97e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-17+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-13+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n",
            "100% 13/13 [00:03<00:00,  3.85it/s, train_loss=0.287]\n",
            "100% 2/2 [00:00<00:00, 10.47it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00072 to 0.00067\n",
            "speechbrain.utils.train_logger - Epoch: 7, lr: 7.16e-04 - train loss: 2.87e-01 - valid loss: 4.35e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n",
            "100% 13/13 [00:04<00:00,  3.10it/s, train_loss=0.187]\n",
            "100% 2/2 [00:00<00:00, 10.44it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00067 to 0.00062\n",
            "speechbrain.utils.train_logger - Epoch: 8, lr: 6.68e-04 - train loss: 1.87e-01 - valid loss: 3.54e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-25+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n",
            "100% 13/13 [00:03<00:00,  3.77it/s, train_loss=0.165]\n",
            "100% 2/2 [00:00<00:00,  9.78it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00062 to 0.00057\n",
            "speechbrain.utils.train_logger - Epoch: 9, lr: 6.21e-04 - train loss: 1.65e-01 - valid loss: 2.74e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-28+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-17+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n",
            "100% 13/13 [00:03<00:00,  3.73it/s, train_loss=0.102]\n",
            "100% 2/2 [00:00<00:00, 10.61it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00057 to 0.00053\n",
            "speechbrain.utils.train_logger - Epoch: 10, lr: 5.74e-04 - train loss: 1.02e-01 - valid loss: 1.92e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n",
            "100% 13/13 [00:04<00:00,  3.02it/s, train_loss=0.0923]\n",
            "100% 2/2 [00:00<00:00,  9.82it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00053 to 0.00048\n",
            "speechbrain.utils.train_logger - Epoch: 11, lr: 5.26e-04 - train loss: 9.23e-02 - valid loss: 1.46e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-37+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-28+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n",
            "100% 13/13 [00:03<00:00,  3.49it/s, train_loss=0.0747]\n",
            "100% 2/2 [00:00<00:00,  6.84it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00048 to 0.00043\n",
            "speechbrain.utils.train_logger - Epoch: 12, lr: 4.79e-04 - train loss: 7.47e-02 - valid loss: 1.46e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-41+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-37+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n",
            "100% 13/13 [00:03<00:00,  3.37it/s, train_loss=0.0756]\n",
            "100% 2/2 [00:00<00:00,  9.81it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00043 to 0.00038\n",
            "speechbrain.utils.train_logger - Epoch: 13, lr: 4.32e-04 - train loss: 7.56e-02 - valid loss: 1.47e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-45+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-41+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n",
            "100% 13/13 [00:04<00:00,  2.63it/s, train_loss=0.0595]\n",
            "100% 2/2 [00:00<00:00, 10.15it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00038 to 0.00034\n",
            "speechbrain.utils.train_logger - Epoch: 14, lr: 3.84e-04 - train loss: 5.95e-02 - valid loss: 1.46e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-50+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n",
            "100% 13/13 [00:03<00:00,  3.80it/s, train_loss=0.0569]\n",
            "100% 2/2 [00:00<00:00, 10.91it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00034 to 0.00029\n",
            "speechbrain.utils.train_logger - Epoch: 15, lr: 3.37e-04 - train loss: 5.69e-02 - valid loss: 1.05e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-54+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-45+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-50+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n",
            "100% 13/13 [00:03<00:00,  3.76it/s, train_loss=0.0514]\n",
            "100% 2/2 [00:00<00:00, 10.51it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00029 to 0.00024\n",
            "speechbrain.utils.train_logger - Epoch: 16, lr: 2.89e-04 - train loss: 5.14e-02 - valid loss: 1.20e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-57+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n",
            "100% 13/13 [00:04<00:00,  3.08it/s, train_loss=0.0616]\n",
            "100% 2/2 [00:00<00:00, 10.79it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00024 to 0.00019\n",
            "speechbrain.utils.train_logger - Epoch: 17, lr: 2.42e-04 - train loss: 6.16e-02 - valid loss: 1.11e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-50-02+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-54+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-49-57+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n",
            "100% 13/13 [00:03<00:00,  3.69it/s, train_loss=0.0593]\n",
            "100% 2/2 [00:00<00:00, 10.71it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00019 to 0.00015\n",
            "speechbrain.utils.train_logger - Epoch: 18, lr: 1.95e-04 - train loss: 5.93e-02 - valid loss: 1.05e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-50-06+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-50-02+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n",
            "100% 13/13 [00:03<00:00,  3.86it/s, train_loss=0.0426]\n",
            "100% 2/2 [00:00<00:00, 10.72it/s]\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.00015 to 0.0001\n",
            "speechbrain.utils.train_logger - Epoch: 19, lr: 1.47e-04 - train loss: 4.26e-02 - valid loss: 1.00e-01, valid error: 0.00e+00\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-50-09+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-50-06+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n",
            "100% 13/13 [00:04<00:00,  3.25it/s, train_loss=0.0484]\n",
            "100% 2/2 [00:00<00:00,  6.93it/s]\n",
            "speechbrain.utils.train_logger - Epoch: 20, lr: 1.00e-04 - train loss: 4.84e-02 - valid loss: 1.00e-01, valid error: 3.85e-02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-50-14+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/TIMIT_tiny/Xvector/MFCCs/1986/save/CKPT+2024-02-23+21-50-09+00\n",
            "100% 2/2 [00:00<00:00,  8.77it/s]\n",
            "speechbrain.utils.train_logger - Epoch loaded: 19 - test loss: 6.66e-02, test error: 0.00e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If everything goes well, you should see a training curve simular to this one:\n",
        "\n",
        "\n",
        "```\n",
        "Epoch: 1, lr: 1.00e-03 - train loss: 2.69 - valid loss: 3.27, valid error: 9.62e-01\n",
        "Epoch: 2, lr: 9.53e-04 - train loss: 1.60 - valid loss: 2.96, valid error: 7.69e-01\n",
        "Epoch: 3, lr: 9.05e-04 - train loss: 1.04 - valid loss: 1.87, valid error: 4.62e-01\n",
        "Epoch: 4, lr: 8.58e-04 - train loss: 6.46e-01 - valid loss: 1.29, valid error: 2.69e-01\n",
        "Epoch: 5, lr: 8.11e-04 - train loss: 4.28e-01 - valid loss: 9.86e-01, valid error: 1.92e-01\n",
        "Epoch: 6, lr: 7.63e-04 - train loss: 2.76e-01 - valid loss: 9.31e-01, valid error: 1.15e-01\n",
        "Epoch: 7, lr: 7.16e-04 - train loss: 2.25e-01 - valid loss: 6.23e-01, valid error: 3.85e-02\n",
        "Epoch: 8, lr: 6.68e-04 - train loss: 1.44e-01 - valid loss: 5.75e-01, valid error: 3.85e-02\n",
        "Epoch: 9, lr: 6.21e-04 - train loss: 1.20e-01 - valid loss: 5.11e-01, valid error: 7.69e-02\n",
        "Epoch: 10, lr: 5.74e-04 - train loss: 8.41e-02 - valid loss: 5.21e-01, valid error: 7.69e-02\n",
        "Epoch: 11, lr: 5.26e-04 - train loss: 8.04e-02 - valid loss: 4.65e-01, valid error: 7.69e-02\n",
        "Epoch: 12, lr: 4.79e-04 - train loss: 7.08e-02 - valid loss: 4.61e-01, valid error: 3.85e-02\n",
        "Epoch: 13, lr: 4.32e-04 - train loss: 6.04e-02 - valid loss: 4.41e-01, valid error: 3.85e-02\n",
        "Epoch: 14, lr: 3.84e-04 - train loss: 5.07e-02 - valid loss: 3.96e-01, valid error: 3.85e-02\n",
        "Epoch: 15, lr: 3.37e-04 - train loss: 4.85e-02 - valid loss: 3.79e-01, valid error: 3.85e-02\n",
        "Epoch: 16, lr: 2.89e-04 - train loss: 4.94e-02 - valid loss: 3.59e-01, valid error: 0.00e+00\n",
        "Epoch: 17, lr: 2.42e-04 - train loss: 5.20e-02 - valid loss: 3.59e-01, valid error: 3.85e-02\n",
        "Epoch: 18, lr: 1.95e-04 - train loss: 5.23e-02 - valid loss: 3.65e-01, valid error: 3.85e-02\n",
        "Epoch: 19, lr: 1.47e-04 - train loss: 3.54e-02 - valid loss: 3.59e-01, valid error: 3.85e-02\n",
        "Epoch: 20, lr: 1.00e-04 - train loss: 4.22e-02 - valid loss: 3.48e-01, valid error: 3.85e-02\n",
        "Epoch loaded: 16 - test loss: 1.55e-01, test error: 0.00e+00\n",
        "```\n",
        "\n",
        "You should reach a perfect classification on both training and validation sets in this case as well.\n",
        "\n",
        "\n",
        "That's all!\n"
      ],
      "metadata": {
        "id": "bnLk14yoRITs"
      }
    }
  ]
}